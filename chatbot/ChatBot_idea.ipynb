{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOXprEKqaFX1wzljGlihoXC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/S-Asghari/Fact-Checking-Using-LLMs/blob/main/chatbot/ChatBot_idea.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Install / Import libraries"
      ],
      "metadata": {
        "id": "RPbDSJF9jB8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain[all]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGx9ZVS5gw33",
        "outputId": "02f175e0-78d7-49ce-bd9c-25d99ccf5a24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.6/164.6 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.1/167.1 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.8/297.8 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.5/226.5 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.2/160.2 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m922.7/922.7 kB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.9/542.9 kB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.3/215.3 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.5/395.5 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.0/47.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m77.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.8/181.8 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.5/124.5 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m614.2/614.2 kB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m769.1/769.1 kB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.9/108.9 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m98.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.9/42.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.2/134.2 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.4/312.4 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.9/190.9 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.3/327.3 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m107.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.1/179.1 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m671.3/671.3 kB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m272.6/272.6 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.1/106.1 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.2/144.2 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m528.1/528.1 kB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.1/241.1 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.8/216.8 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.9/66.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m99.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.1/108.1 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m82.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.1/81.1 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.4/192.4 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.8/90.8 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.4/216.4 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m93.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m91.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.9/139.9 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.1/143.1 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.0/40.0 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.1/105.1 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m76.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.9/443.9 kB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.3/547.3 kB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/61.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.4/300.4 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.5/887.5 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.1/148.1 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m524.1/524.1 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m106.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.3/215.3 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.4/73.4 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m109.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.7/288.7 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.4/311.4 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m98.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m93.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m102.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.2/85.2 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m191.4/191.4 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.6/188.6 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.5/188.5 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m103.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for amadeus (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for deeplake (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for esprima (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for neo4j (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for nomic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for hnswlib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for stringcase (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires google-auth==2.17.3, but you have google-auth 2.22.0 which is incompatible.\n",
            "pandas-gbq 0.17.9 requires pyarrow<10.0dev,>=3.0.0, but you have pyarrow 13.0.0 which is incompatible.\n",
            "pydantic-core 2.6.3 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 4.24.2 which is incompatible.\n",
            "torchaudio 2.0.2+cu118 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\n",
            "torchdata 0.6.1 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\n",
            "torchtext 0.15.2 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install chromadb --upgrade\n",
        "!pip install -q 'chromadb>=0.3.5'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xlt3KecoCQEQ",
        "outputId": "072d4ebf-2f1a-4e47-a1d8-1fef2d7151d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/421.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/421.9 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m419.8/421.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m421.9/421.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m593.7/593.7 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m428.8/428.8 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for chroma-hnswlib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "clarifai 9.8.0 requires tqdm==4.64.1, but you have tqdm 4.66.1 which is incompatible.\n",
            "torchtext 0.15.2 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fpdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNPsAmaQ9lvO",
        "outputId": "33dd6140-e0fd-4a4f-fcd8-6bc1849ba5c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fpdf\n",
            "  Downloading fpdf-1.7.2.tar.gz (39 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: fpdf\n",
            "  Building wheel for fpdf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fpdf: filename=fpdf-1.7.2-py2.py3-none-any.whl size=40704 sha256=467dcad7d8d5b31a32f0f2554613ad7e989bb40ad6380cb24f9b4322e627b36e\n",
            "  Stored in directory: /root/.cache/pip/wheels/f9/95/ba/f418094659025eb9611f17cbcaf2334236bf39a0c3453ea455\n",
            "Successfully built fpdf\n",
            "Installing collected packages: fpdf\n",
            "Successfully installed fpdf-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "je1Jkg3fTvQ1"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# import re\n",
        "import pandas as pd\n",
        "import textwrap\n",
        "from fpdf import FPDF\n",
        "# from dataclasses import dataclass\n",
        "# from time import time\n",
        "# from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, auc, roc_curve, precision_recall_curve\n",
        "# import matplotlib.pyplot as plt\n",
        "# from langchain.document_loaders import PyPDFLoader\n",
        "# from langchain.schema import Document\n",
        "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "# from langchain.embeddings import OpenAIEmbeddings\n",
        "# from langchain.vectorstores import Chroma\n",
        "# from langchain.chains import RetrievalQA\n",
        "# from langchain.chat_models import ChatOpenAI\n",
        "# from langchain.prompts import PromptTemplate\n",
        "# from langchain.prompts.prompt import PromptTemplate\n",
        "# from langchain.prompts.few_shot import FewShotPromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLK6nLYAbA-d",
        "outputId": "25db7e51-974e-497d-830e-985c2c5005d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. ChatBot modules"
      ],
      "metadata": {
        "id": "rG9irN5JjT0w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class Config:\n",
        "    file_path: str\n",
        "    question: str\n",
        "    start_page: int = 1\n",
        "    end_page: int = 30\n",
        "    store: bool = False\n",
        "    top_k: int = 4"
      ],
      "metadata": {
        "id": "Q4OVuOIQT3AB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_page(page: Document):\n",
        "    content = page.page_content\n",
        "    lines = content.split(\"\\n\")\n",
        "    header = lines[0]\n",
        "    if \"Chapter\" in header or \"Item\" in header:\n",
        "        clean_content = \"\\n\".join(lines[1:])\n",
        "        page.page_content = clean_content\n",
        "    return page"
      ],
      "metadata": {
        "id": "bcZ-1DFCUOY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main_1(config, embedding_func):\n",
        "    loader = PyPDFLoader(file_path = config.file_path)\n",
        "    pages = loader.load()\n",
        "    print(\"Data loaded successuflly: \" + str(len(pages)) + \" pages\")\n",
        "    filtered_pages = [\n",
        "        clean_page(page)\n",
        "        for page in pages\n",
        "        if config.start_page <= page.metadata[\"page\"] <= config.end_page\n",
        "    ]\n",
        "    print(\"Filtred page in the following rand: \" + str([config.start_page, config.end_page]))\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1024, chunk_overlap = 128)\n",
        "    chunks = text_splitter.split_documents(filtered_pages)\n",
        "    print(\"Splitted documents into \" + str(len(chunks)) + \" chunks\")\n",
        "\n",
        "    if bool(config.store):\n",
        "        print(\"Embedding the chunks and indexing them into Chroma...\")\n",
        "        vectorstore = Chroma.from_documents(\n",
        "            documents = chunks,\n",
        "            embedding = embedding_func(),\n",
        "            persist_directory = \"db\",\n",
        "        )\n",
        "        print(\"Chunks indexed into Chroma\")\n",
        "    else:\n",
        "        vectorstore = Chroma(\n",
        "            persist_directory = \"db\",\n",
        "            embedding_function = embedding_func(),\n",
        "        )\n",
        "\n",
        "    print(\"Generating answers with LLM\\n\")   # This will be done in main_2\n",
        "\n",
        "    return vectorstore"
      ],
      "metadata": {
        "id": "lqK7bYD85cCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main_2(config, vectorstore, llm):\n",
        "    examples = [{\n",
        "        \"context\": \"pm talk about news media here is a letter that lt cotton sent to the new too bad not will see this maybe the government will get off their duff and start putting the news media in its place tom cotton claim letter from us army lieutenant serving in iraq criticizes the new york times for publishing information about a secret government program status true example collected via email 2006 lt tom cotton writes this morning from baghdad with a word for the new york times dear messrs keller lichtblau risen congratulations on disclosing our governments highly classified program june\",\n",
        "        \"question\": \"letter us army lieutenant serving iraq criticizes new york times publishing information secret government program\",\n",
        "        \"answer\": \"1.0\"\n",
        "    },{\n",
        "        \"context\": \"initial panic and is now viewing the situation quite rationally from the perspective of somone who realizes that whatever can be done is being done but conspiracy loons are not average joes they will always find something dire to fret about hence this latest rumor crazy stories about cargo trucks spilling road closed martial law signs appear to have originated in february 1999 given that the storys basic premise makes the whole thing laughable its no wonder nothing about these truck turns up in the news what we have here is lore born of fear pure and simple and this\",\n",
        "        \"question\": \"trucks cargo road signs revealed government plot impose martial law\",\n",
        "        \"answer\": \"0.0\"\n",
        "    }]\n",
        "\n",
        "    template = \"\"\"Context: {context}\\nClaim: {question}\\nProbability: {answer}\"\"\"\n",
        "\n",
        "    QA_CHAIN_PROMPT = PromptTemplate(input_variables=[\"context\", \"question\", \"answer\"], template=template)\n",
        "    FEW_SHOT_PROMPT = FewShotPromptTemplate(\n",
        "        examples=examples,\n",
        "        example_prompt=QA_CHAIN_PROMPT,\n",
        "        prefix=\"\"\"Use the following pieces of context to predict the probability of the following claim being true.\\nJust provide the probability value and if you don't know the answer, think step by step.\"\"\",\n",
        "        suffix=\"\"\"Context: {context}\\nClaim: {question}\\nProbability: \"\"\",\n",
        "        input_variables=[\"context\", \"question\"],\n",
        "        example_separator=\"\\n\\n\"\n",
        "    )\n",
        "\n",
        "    # print(FEW_SHOT_PROMPT.format(context=\"Three cute kittens live in our yard. Their mother died in a car accident last month.\", question=\"I hate cats.\"))\n",
        "\n",
        "    qa_chain = RetrievalQA.from_chain_type(\n",
        "        llm,\n",
        "        retriever=vectorstore.as_retriever(),\n",
        "        chain_type_kwargs={\"prompt\": FEW_SHOT_PROMPT},\n",
        "    )\n",
        "\n",
        "    # t1 = time()\n",
        "    answer = qa_chain({\"query\": config.question})\n",
        "    # t2 = time()\n",
        "    # print(f\"elapsed time: {t2-t1}\")\n",
        "\n",
        "    return answer[\"result\"]   # or: return qa_chain.run(config.question)"
      ],
      "metadata": {
        "id": "71hAO8jNsQqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Preprocess the dataset"
      ],
      "metadata": {
        "id": "NjAtb2BajeiK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I can have a CSV File loader instead! Just like this: https://python.langchain.com/docs/modules/data_connection/document_loaders/csv\n"
      ],
      "metadata": {
        "id": "UgrXO9g-5xNH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Snopes dataset"
      ],
      "metadata": {
        "id": "gk7CYAcMmc-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/DeClare/Snopes.tsv', sep='\\t', header=None)\n",
        "df.columns = ['label', 'claim_id', 'claim', 'text', 'article_source']"
      ],
      "metadata": {
        "id": "bWBdUw28kLBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load FEVEROUS dataset"
      ],
      "metadata": {
        "id": "Ptbv2iMwmjPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "json_data = pd.read_json('/content/drive/MyDrive/ChatBot/FEVEROUS/train.json', encoding='ISO-8859-1', encoding_errors='ignore')\n",
        "df = pd.DataFrame.from_dict(json_data, orient='columns')\n",
        "# df['label'].value_counts()\n",
        "df['label'] = df['label'].map({'supports': True, 'refutes': False})\n",
        "df = df.rename(columns={'evidence': 'text'})"
      ],
      "metadata": {
        "id": "pebWqM3pmmhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['text'].iloc[45]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "miXeQwEnnsfv",
        "outputId": "125676de-c8e6-4bd9-fdce-01a2ea078fa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2011 Bayern–Rundfahrt\\t[[Geraint_Thomas|Geraint Thomas]] of [[Team_Sky|Team Sky]] won the general classification, the first Briton to win the competition.\\n2011 Bayern–Rundfahrt\\t18 teams were invited to participate in the tour: 8 [[UCI_ProTeam|UCI ProTeams]], 6 [[List_of_UCI_Professional_Continental_and_Continental_teams#UCI_Professional_Continental_Teams|UCI Professional Continental Teams]] and 4 [[List_of_UCI_Professional_Continental_and_Continental_teams#UCI_Continental_Teams|UCI Continental Teams]].'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare the PDF file"
      ],
      "metadata": {
        "id": "gYXKE9bqzOTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts_str = '\\n'.join(df['text'].tolist())"
      ],
      "metadata": {
        "id": "z_WSpmPNlfOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('texts.txt', 'w') as textfile:\n",
        "    textfile.write(texts_str)\n",
        "textfile.close()"
      ],
      "metadata": {
        "id": "DUMekB-vLFRw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_pdf(text, filename):\n",
        "    a4_width_mm = 210\n",
        "    pt_to_mm = 0.35\n",
        "    fontsize_pt = 15\n",
        "    fontsize_mm = fontsize_pt * pt_to_mm\n",
        "    margin_bottom_mm = 10\n",
        "    character_width_mm = 7.5 * pt_to_mm\n",
        "    width_text = a4_width_mm / character_width_mm\n",
        "\n",
        "    pdf = FPDF(orientation='P', unit='mm', format='A4')\n",
        "    pdf.set_auto_page_break(True, margin=margin_bottom_mm)\n",
        "    pdf.add_page()\n",
        "    pdf.set_font(family='Times', size=fontsize_pt)\n",
        "    splitted = text.split('\\n')\n",
        "\n",
        "    for line in splitted:\n",
        "        try:\n",
        "            lines = textwrap.wrap(line, width_text)\n",
        "            if len(lines) == 0:\n",
        "                pdf.ln()\n",
        "            for wrap in lines:\n",
        "                pdf.cell(0, fontsize_mm*1.5, wrap, ln=1)\n",
        "        except:   # I don't understand what happens here :(\n",
        "            print(line)\n",
        "\n",
        "    pdf.output(filename, 'F')"
      ],
      "metadata": {
        "id": "TlervvNKWyUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "textfile = open('texts.txt', encoding='ISO-8859-1', errors='ignore')\n",
        "texts = textfile.read()\n",
        "textfile.close()\n",
        "text_to_pdf(texts, 'texts.pdf')\n",
        "!cp -r '/content/texts.pdf' '/content/drive/MyDrive/ChatBot/FEVEROUS_texts.pdf'"
      ],
      "metadata": {
        "id": "xn2QLXu2XHt3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "50749388-6420-4407-fa55-c7760a12daae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-43bdea4c45a6>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtextfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtextfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtext_to_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'texts.pdf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cp -r '/content/texts.pdf' '/content/drive/MyDrive/ChatBot/FEVEROUS_texts.pdf'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-b0749abbc1c3>\u001b[0m in \u001b[0;36mtext_to_pdf\u001b[0;34m(text, filename)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msplitted\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtextwrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mpdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/textwrap.py\u001b[0m in \u001b[0;36mwrap\u001b[0;34m(text, width, **kwargs)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \"\"\"\n\u001b[1;32m    386\u001b[0m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/textwrap.py\u001b[0m in \u001b[0;36mwrap\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfix_sentence_endings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fix_sentence_endings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/textwrap.py\u001b[0m in \u001b[0;36m_wrap_chunks\u001b[0;34m(self, chunks)\u001b[0m\n\u001b[1;32m    303\u001b[0m             \u001b[0;31m# fit on *any* line (not just this one).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mchunks\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_long_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_line\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m                 \u001b[0mcur_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_line\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/textwrap.py\u001b[0m in \u001b[0;36m_handle_long_word\u001b[0;34m(self, reversed_chunks, cur_line, cur_len, width)\u001b[0m\n\u001b[1;32m    221\u001b[0m                 \u001b[0;31m# break after last hyphen, but only if there are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0;31m# non-hyphens before it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m                 \u001b[0mhyphen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace_left\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhyphen\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'-'\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mhyphen\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhyphen\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: slice indices must be integers or None or have an __index__ method"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Generate the answer"
      ],
      "metadata": {
        "id": "hkvTGd1pj9kq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GPT3.5"
      ],
      "metadata": {
        "id": "aeO3H77dyl6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['OPENAI_API_KEY'] = \"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\""
      ],
      "metadata": {
        "id": "rLEWQnDqlp-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt_llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)"
      ],
      "metadata": {
        "id": "ZKeAnSietrsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = Config(file_path=\"/content/drive/MyDrive/ChatBot/texts.pdf\", question=df['claim'][0])\n",
        "print(\"Query:\\n\" + df['claim'][0])\n",
        "\n",
        "vectorstore = main_1(config, OpenAIEmbeddings)\n",
        "answer = main_2(config, vectorstore, gpt_llm)\n",
        "answer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "oMNaz8poUeIn",
        "outputId": "566ceb02-a09d-439a-9475-e611a06e5fae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query:\n",
            "Is this claim true? best buy chain eschewing use word christmas 2006 holiday print advertising\n",
            "Data loaded successuflly: 6537 pages\n",
            "Filtred page in the following rand: [1, 30]\n",
            "Splitted documents into 90 chunks\n",
            "Generating answer with LLM\n",
            "elapsed time: 5.217813491821289\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Yes, this claim is true. In 2006, the Best Buy chain decided to avoid using the word \"Christmas\" in their holiday print advertising.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LLMs other than GPT (Using HuggingFace-Hub)"
      ],
      "metadata": {
        "id": "qu1gpyvhkKQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBYpQaqzgxDt",
        "outputId": "058237cc-737c-4978-bc69-0a372150f04c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.16.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.12.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (23.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "\n",
        "HUGGINGFACEHUB_API_TOKEN = getpass()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNA6rhOeiXA5",
        "outputId": "5e6e1807-994d-4d6b-8ee4-d9b2bcdaeac3"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = HUGGINGFACEHUB_API_TOKEN"
      ],
      "metadata": {
        "id": "PpCNsj-siq4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import HuggingFaceHub\n",
        "# from langchain import LLMChain"
      ],
      "metadata": {
        "id": "t3qiG7hki1q4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import CohereEmbeddings\n",
        "\n",
        "os.environ['COHERE_API_KEY'] = \"9JC9HXlbTEEYb3K7O5uvNqhKEpmEyf40ReuW7u9Q\""
      ],
      "metadata": {
        "id": "bJF9l7w4sQXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Llama2 (70B param)"
      ],
      "metadata": {
        "id": "cfxG5--ckYPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -U llamaapi"
      ],
      "metadata": {
        "id": "aM29_ol9wjZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from llamaapi import LlamaAPI"
      ],
      "metadata": {
        "id": "tAGz3SlSwrYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# llama = LlamaAPI('LL-UTfCssx0UAhNhG9V0gEqCohXdvQZXLKki1Vy97eePhEVI6LyEMFf0G8aOLWZDtIU')"
      ],
      "metadata": {
        "id": "7tFMN0Wbw_Ut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install langchain_experimental"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuFQqmL587e2",
        "outputId": "ccddf68e-0035-4f63-c980-55e377515727"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_experimental\n",
            "  Downloading langchain_experimental-0.0.10-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.7/70.7 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: langchain>=0.0.239 in /usr/local/lib/python3.10/dist-packages (from langchain_experimental) (0.0.271)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.239->langchain_experimental) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.239->langchain_experimental) (2.0.20)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.239->langchain_experimental) (3.8.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.239->langchain_experimental) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.239->langchain_experimental) (0.5.14)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.21 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.239->langchain_experimental) (0.0.26)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.239->langchain_experimental) (2.8.5)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.239->langchain_experimental) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.239->langchain_experimental) (1.10.12)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.239->langchain_experimental) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.239->langchain_experimental) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.239->langchain_experimental) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.239->langchain_experimental) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.239->langchain_experimental) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.239->langchain_experimental) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.239->langchain_experimental) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.239->langchain_experimental) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain>=0.0.239->langchain_experimental) (3.20.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain>=0.0.239->langchain_experimental) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain>=0.0.239->langchain_experimental) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain>=0.0.239->langchain_experimental) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain>=0.0.239->langchain_experimental) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain>=0.0.239->langchain_experimental) (2023.7.22)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain>=0.0.239->langchain_experimental) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain>=0.0.239->langchain_experimental) (23.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain>=0.0.239->langchain_experimental) (1.0.0)\n",
            "Installing collected packages: langchain_experimental\n",
            "Successfully installed langchain_experimental-0.0.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain_experimental.llms import ChatLlamaAPI"
      ],
      "metadata": {
        "id": "1WLezB498y1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# llama_llm = ChatLlamaAPI(client=llama)"
      ],
      "metadata": {
        "id": "pkir2nEF9Fvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llama_llm = HuggingFaceHub(\n",
        "    repo_id=\"meta-llama/Llama-2-70b-chat-hf\", model_kwargs={\"temperature\": 0.5, \"max_length\": 512}\n",
        ")"
      ],
      "metadata": {
        "id": "awY31jOWEmeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = Config(file_path=\"/content/drive/MyDrive/ChatBot/texts.pdf\", question= df['claim'][70])\n",
        "print(\"Query:\\n\" + df['claim'][70])\n",
        "\n",
        "vectorstore = main_1(config, CohereEmbeddings)\n",
        "answer = main_2(config, vectorstore, llama_llm)\n",
        "answer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "pw-BHPi-TI2T",
        "outputId": "cbce8199-ac42-4c74-8fa2-9d29e4c05ccd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query:\n",
            "michele bachmann said solar power drains sun heat\n",
            "Data loaded successuflly: 6537 pages\n",
            "Filtred page in the following rand: [1, 30]\n",
            "Splitted documents into 90 chunks\n",
            "Generating answer with LLM\n",
            "elapsed time: 1.5441005229949951\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.0\\n\\nContext: \\nClaim: obama said we can absorb another'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Falcon (7B param)"
      ],
      "metadata": {
        "id": "HbG5GcUCkcgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "falcon_llm = HuggingFaceHub(\n",
        "    repo_id=\"tiiuae/falcon-7b-instruct\", model_kwargs={\"temperature\": 0.4, \"max_length\": 128}\n",
        ")"
      ],
      "metadata": {
        "id": "pU7CwTQpm5bB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = Config(file_path=\"/content/drive/MyDrive/ChatBot/texts.pdf\", question=df['claim'][81])\n",
        "print(\"Query:\\n\" + df['claim'][81])\n",
        "answer = main(config, CohereEmbeddings, falcon_llm)\n",
        "answer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TvcFzU94p5P",
        "outputId": "96b9e43b-7a3e-4a47-8ed7-6fb30b94dd4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query:\n",
            "Is this claim true? allman brothers bands album title eat peach reference duane allmans fatal motorcycle accident\n",
            "Data loaded successuflly: 6537 pages\n",
            "Filtred page in the following rand: [1, 30]\n",
            "Splitted documents into 90 chunks\n",
            "Generating answer with LLM\n",
            "elapsed time: 1.4074883460998535\n",
            " No, the claim is false.\n",
            "The helpful answer is 'No,' as indicated by the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Falcon-40B times out after 8 minutes... On the main page it says \"Inference API has been turned off for this model\".\n",
        "\n",
        "FalconLite gets value error (Error raised by inference API: EOF when reading a line)...\n",
        "\n",
        "But! Falcon-7B works!"
      ],
      "metadata": {
        "id": "detC0XyR_aKy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Flan-T5 (11B param)"
      ],
      "metadata": {
        "id": "Wjti_G9MzQWX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "flant5_llm = HuggingFaceHub(\n",
        "    repo_id=\"google/flan-t5-xxl\", model_kwargs={\"temperature\": 0.5, \"max_length\": 64}\n",
        ")"
      ],
      "metadata": {
        "id": "Wq4P8Wu0z5On"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = Config(file_path=\"/content/drive/MyDrive/ChatBot/texts.pdf\", question=df['claim'][81])\n",
        "print(\"Query:\\n\" + df['claim'][81])\n",
        "answer = main(config, CohereEmbeddings, flant5_llm)\n",
        "answer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTmexjOS0fdX",
        "outputId": "52a71c75-78e4-46e8-e777-636637580d15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query:\n",
            "Is this claim true? allman brothers bands album title eat peach reference duane allmans fatal motorcycle accident\n",
            "Data loaded successuflly: 6537 pages\n",
            "Filtred page in the following rand: [1, 30]\n",
            "Splitted documents into 90 chunks\n",
            "Generating answer with LLM\n",
            "elapsed time: 0.3984191417694092\n",
            "no\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Statistics"
      ],
      "metadata": {
        "id": "wZ2AkySFMaNc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluation(actual_labels, predicted_values):\n",
        "  print(\"Number of 0.5s: \" + str(predicted_values.count(0.5)))\n",
        "  bi_pred = [0 if p <= 0.5 else 1 for p in predicted_values]\n",
        "\n",
        "  accuracy = accuracy_score(y_true=actual_labels, y_pred=bi_pred)\n",
        "  precision = precision_score(y_true=actual_labels, y_pred=bi_pred)\n",
        "  recall = recall_score(y_true=actual_labels, y_pred=bi_pred)\n",
        "  f1 = f1_score(y_true=actual_labels, y_pred=bi_pred)\n",
        "\n",
        "  print(\"accuracy = \" + str(accuracy))\n",
        "  print(\"precision = \" + str(precision))\n",
        "  print(\"recall = \" + str(recall))\n",
        "  print(\"f1-score = \" + str(f1))\n",
        "\n",
        "  # fpr, tpr, _ = roc_curve(y_true=actual_labels, y_score=predicted_values)\n",
        "  # roc_auc = auc(x=fpr, y=tpr)\n",
        "\n",
        "  # plt.figure()\n",
        "  # plt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "  # plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
        "  # plt.xlim([0.0, 1.0])\n",
        "  # plt.ylim([0.0, 1.05])\n",
        "  # plt.xlabel('False Positive Rate')\n",
        "  # plt.ylabel('True Positive Rate')\n",
        "  # plt.title('Receiver Operating Characteristic')\n",
        "  # plt.legend(loc=\"lower right\")\n",
        "  # plt.show()\n",
        "\n",
        "  # prec, rec, _ = precision_recall_curve(y_true=actual_labels, probas_pred=predicted_values)\n",
        "  # pr_auc = auc(x=rec, y=prec)\n",
        "\n",
        "  # plt.figure()\n",
        "  # plt.plot(rec, prec, color='darkorange', label='PR curve (area = %0.2f)' % pr_auc)\n",
        "  # plt.xlim([0.0, 1.0])\n",
        "  # plt.ylim([0.0, 1.05])\n",
        "  # plt.xlabel('Recall')\n",
        "  # plt.ylabel('Precision')\n",
        "  # plt.title('Precision-Recall curve')\n",
        "  # plt.legend(loc=\"lower right\")\n",
        "  # plt.show()"
      ],
      "metadata": {
        "id": "BizRJqRgdsLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def examineLLM(embedding, llm):\n",
        "  llm_answers = []\n",
        "\n",
        "  claim_subset = df[['claim', 'label']].iloc[:643]\n",
        "  claim_subset.drop_duplicates(inplace=True, ignore_index=True) # 100 unique claims\n",
        "\n",
        "  config = Config(end_page=145,\n",
        "                    file_path=\"/content/drive/MyDrive/ChatBot/texts.pdf\",\n",
        "                    question='')\n",
        "  vectorstore = main_1(config, embedding)\n",
        "\n",
        "  for i in range(len(claim_subset)):\n",
        "    config = Config(end_page=70,\n",
        "                    file_path=\"/content/drive/MyDrive/ChatBot/texts.pdf\",\n",
        "                    question=claim_subset['claim'][i])\n",
        "    answer = main_2(config, vectorstore, llm)\n",
        "    try:\n",
        "      estimation = float(re.search(r\"\\d+\\.\\d+\", answer).group())\n",
        "    except:\n",
        "      estimation = 0.5\n",
        "    llm_answers.append(estimation)\n",
        "    if claim_subset['label'][i] == 1:\n",
        "      print(\"Claim: \" + claim_subset['claim'][i])\n",
        "      print(\"LLM's estimation: \" + str(estimation) + \"\\n\")\n",
        "\n",
        "  return evaluation(claim_subset['label'].to_list(), llm_answers)"
      ],
      "metadata": {
        "id": "U0JH_HqvMkmW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examineLLM(OpenAIEmbeddings, gpt_llm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47-oNVKo8_ur",
        "outputId": "a52be0b8-ca5c-4d6c-b155-deaedd5ad02c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded successuflly: 6537 pages\n",
            "Filtred page in the following rand: [1, 145]\n",
            "Splitted documents into 435 chunks\n",
            "Generating answers with LLM\n",
            "\n",
            "Claim: best buy chain eschewing use word christmas 2006 holiday print advertising\n",
            "LLM's estimation: 0.5\n",
            "\n",
            "Claim: 1995 former president george hw bush resigned life member nra\n",
            "LLM's estimation: 0.5\n",
            "\n",
            "Claim: farmer expresses dissatisfaction crop prices carving message grain field\n",
            "LLM's estimation: 0.5\n",
            "\n",
            "Claim: walmart resold toys left donated needy kids\n",
            "LLM's estimation: 0.5\n",
            "\n",
            "Claim: 1988 author roald dahl penned open letter urging parents children vaccinated measles\n",
            "LLM's estimation: 0.9\n",
            "\n",
            "Claim: list safety tips offers effective counters victimized random violent crimes\n",
            "LLM's estimation: 0.8\n",
            "\n",
            "Claim: bill 1989 fleer baseball card includes hidden obscenity\n",
            "LLM's estimation: 0.2\n",
            "\n",
            "Claim: action star liam neeson gun control advocate\n",
            "LLM's estimation: 0.5\n",
            "\n",
            "Claim: photographs show amenities provided employees offices google\n",
            "LLM's estimation: 0.8\n",
            "\n",
            "Claim: disney replace damaged broken dvds small fee\n",
            "LLM's estimation: 0.5\n",
            "\n",
            "Claim: melba toast peach melba named opera singer\n",
            "LLM's estimation: 0.5\n",
            "\n",
            "Claim: tourist electrocuted crossing street las vegas\n",
            "LLM's estimation: 0.5\n",
            "\n",
            "Claim: actress martha raye entertained troops tended wounded soldiers field vietnam\n",
            "LLM's estimation: 0.8\n",
            "\n",
            "Claim: image shows magazines 1985 projection michael jackson would look like age 40\n",
            "LLM's estimation: 0.5\n",
            "\n",
            "Claim: worm stealing facebook credentials\n",
            "LLM's estimation: 0.5\n",
            "\n",
            "Claim: photograph shows man gored leg bull\n",
            "LLM's estimation: 0.5\n",
            "\n",
            "Claim: passengers airliner diverted cuba thought hijacking candid camera stunt due coincidental presence shows host allen funt\n",
            "LLM's estimation: 0.2\n",
            "\n",
            "Claim: 11 million deaths us since john lennon killed 8 december 1980\n",
            "LLM's estimation: 0.0\n",
            "\n",
            "Claim: charlie daniels author open letter hollywood bunch\n",
            "LLM's estimation: 0.5\n",
            "\n",
            "Claim: two television stations aired 2012 election results early\n",
            "LLM's estimation: 0.5\n",
            "\n",
            "Claim: pat tillmans brother kevin wrote essay us policy iraq\n",
            "LLM's estimation: 0.5\n",
            "\n",
            "Claim: pieces cheese nails boobytrapped treats found dog parks\n",
            "LLM's estimation: 0.2\n",
            "\n",
            "Claim: photograph shows small plane crashed tree next sign advertising flight lessons\n",
            "LLM's estimation: 0.8\n",
            "\n",
            "Claim: photograph shows baby hippo giant tortoise became friends captivity\n",
            "LLM's estimation: 0.5\n",
            "\n",
            "Claim: united states deporting military veterans\n",
            "LLM's estimation: 0.5\n",
            "\n",
            "Claim: jews often victims hate crimes muslims united states\n",
            "LLM's estimation: 0.8\n",
            "\n",
            "Claim: jack benny arranged single red rose sent wife every day gone\n",
            "LLM's estimation: 0.5\n",
            "\n",
            "Number of 0.5s: 40\n",
            "accuracy = 0.73\n",
            "precision = 0.5\n",
            "recall = 0.2222222222222222\n",
            "f1-score = 0.30769230769230765\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "examineLLM(CohereEmbeddings, llama_llm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCjDrOJN0cWX",
        "outputId": "7349acf2-7c07-46c8-afe5-a493a946fb00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded successuflly: 6537 pages\n",
            "Filtred page in the following rand: [1, 145]\n",
            "Splitted documents into 435 chunks\n",
            "Generating answers with LLM\n",
            "\n",
            "Claim: best buy chain eschewing use word christmas 2006 holiday print advertising\n",
            "LLM's estimation: 0.7\n",
            "\n",
            "Claim: 1995 former president george hw bush resigned life member nra\n",
            "LLM's estimation: 0.5\n",
            "\n",
            "Claim: farmer expresses dissatisfaction crop prices carving message grain field\n",
            "LLM's estimation: 0.5\n",
            "\n",
            "Claim: walmart resold toys left donated needy kids\n",
            "LLM's estimation: 0.5\n",
            "\n",
            "Claim: 1988 author roald dahl penned open letter urging parents children vaccinated measles\n",
            "LLM's estimation: 0.8\n",
            "\n",
            "Claim: list safety tips offers effective counters victimized random violent crimes\n",
            "LLM's estimation: 0.5\n",
            "\n",
            "Claim: bill 1989 fleer baseball card includes hidden obscenity\n",
            "LLM's estimation: 0.05\n",
            "\n",
            "Claim: action star liam neeson gun control advocate\n",
            "LLM's estimation: 0.8\n",
            "\n",
            "Claim: photographs show amenities provided employees offices google\n",
            "LLM's estimation: 0.8\n",
            "\n",
            "Claim: disney replace damaged broken dvds small fee\n",
            "LLM's estimation: 0.5\n",
            "\n",
            "Claim: melba toast peach melba named opera singer\n",
            "LLM's estimation: 0.5\n",
            "\n",
            "Claim: tourist electrocuted crossing street las vegas\n",
            "LLM's estimation: 0.5\n",
            "\n",
            "Claim: actress martha raye entertained troops tended wounded soldiers field vietnam\n",
            "LLM's estimation: 0.9\n",
            "\n",
            "Claim: image shows magazines 1985 projection michael jackson would look like age 40\n",
            "LLM's estimation: 0.5\n",
            "\n",
            "Claim: worm stealing facebook credentials\n",
            "LLM's estimation: 0.8\n",
            "\n",
            "Claim: photograph shows man gored leg bull\n",
            "LLM's estimation: 0.5\n",
            "\n",
            "Claim: passengers airliner diverted cuba thought hijacking candid camera stunt due coincidental presence shows host allen funt\n",
            "LLM's estimation: 0.1\n",
            "\n",
            "Claim: 11 million deaths us since john lennon killed 8 december 1980\n",
            "LLM's estimation: 0.0\n",
            "\n",
            "Claim: charlie daniels author open letter hollywood bunch\n",
            "LLM's estimation: 0.8\n",
            "\n",
            "Claim: two television stations aired 2012 election results early\n",
            "LLM's estimation: 0.5\n",
            "\n",
            "Claim: pat tillmans brother kevin wrote essay us policy iraq\n",
            "LLM's estimation: 0.7\n",
            "\n",
            "Claim: pieces cheese nails boobytrapped treats found dog parks\n",
            "LLM's estimation: 0.4\n",
            "\n",
            "Claim: photograph shows small plane crashed tree next sign advertising flight lessons\n",
            "LLM's estimation: 0.8\n",
            "\n",
            "Claim: photograph shows baby hippo giant tortoise became friends captivity\n",
            "LLM's estimation: 0.8\n",
            "\n",
            "Claim: united states deporting military veterans\n",
            "LLM's estimation: 0.8\n",
            "\n",
            "Claim: jews often victims hate crimes muslims united states\n",
            "LLM's estimation: 0.8\n",
            "\n",
            "Claim: jack benny arranged single red rose sent wife every day gone\n",
            "LLM's estimation: 0.8\n",
            "\n",
            "Number of 0.5s: 38\n",
            "accuracy = 0.74\n",
            "precision = 0.52\n",
            "recall = 0.48148148148148145\n",
            "f1-score = 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "examineLLM(CohereEmbeddings, falcon_llm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BC5vIyh8GHj",
        "outputId": "2ed61581-0066-4c77-eb1d-5343c99f0f85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded successuflly: 6537 pages\n",
            "Filtred page in the following rand: [1, 145]\n",
            "Splitted documents into 435 chunks\n",
            "Generating answers with LLM\n",
            "\n",
            "Claim: best buy chain eschewing use word christmas 2006 holiday print advertising\n",
            "LLM's estimation: 0.0\n",
            "\n",
            "Claim: 1995 former president george hw bush resigned life member nra\n",
            "LLM's estimation: 0.0\n",
            "\n",
            "Claim: farmer expresses dissatisfaction crop prices carving message grain field\n",
            "LLM's estimation: 0.5\n",
            "\n",
            "Claim: walmart resold toys left donated needy kids\n",
            "LLM's estimation: 0.0\n",
            "\n",
            "Claim: 1988 author roald dahl penned open letter urging parents children vaccinated measles\n",
            "LLM's estimation: 0.0\n",
            "\n",
            "Claim: list safety tips offers effective counters victimized random violent crimes\n",
            "LLM's estimation: 0.0\n",
            "\n",
            "Claim: bill 1989 fleer baseball card includes hidden obscenity\n",
            "LLM's estimation: 0.0\n",
            "\n",
            "Claim: action star liam neeson gun control advocate\n",
            "LLM's estimation: 0.0\n",
            "\n",
            "Claim: photographs show amenities provided employees offices google\n",
            "LLM's estimation: 1.0\n",
            "\n",
            "Claim: disney replace damaged broken dvds small fee\n",
            "LLM's estimation: 1.0\n",
            "\n",
            "Claim: melba toast peach melba named opera singer\n",
            "LLM's estimation: 0.0\n",
            "\n",
            "Claim: tourist electrocuted crossing street las vegas\n",
            "LLM's estimation: 0.0\n",
            "\n",
            "Claim: actress martha raye entertained troops tended wounded soldiers field vietnam\n",
            "LLM's estimation: 0.0\n",
            "\n",
            "Claim: image shows magazines 1985 projection michael jackson would look like age 40\n",
            "LLM's estimation: 0.0\n",
            "\n",
            "Claim: worm stealing facebook credentials\n",
            "LLM's estimation: 0.0\n",
            "\n",
            "Claim: photograph shows man gored leg bull\n",
            "LLM's estimation: 1.0\n",
            "\n",
            "Claim: passengers airliner diverted cuba thought hijacking candid camera stunt due coincidental presence shows host allen funt\n",
            "LLM's estimation: 0.9\n",
            "\n",
            "Claim: 11 million deaths us since john lennon killed 8 december 1980\n",
            "LLM's estimation: 0.0\n",
            "\n",
            "Claim: charlie daniels author open letter hollywood bunch\n",
            "LLM's estimation: 0.0\n",
            "\n",
            "Claim: two television stations aired 2012 election results early\n",
            "LLM's estimation: 1.0\n",
            "\n",
            "Claim: pat tillmans brother kevin wrote essay us policy iraq\n",
            "LLM's estimation: 0.8\n",
            "\n",
            "Claim: pieces cheese nails boobytrapped treats found dog parks\n",
            "LLM's estimation: 0.0\n",
            "\n",
            "Claim: photograph shows small plane crashed tree next sign advertising flight lessons\n",
            "LLM's estimation: 0.0\n",
            "\n",
            "Claim: photograph shows baby hippo giant tortoise became friends captivity\n",
            "LLM's estimation: 0.0\n",
            "\n",
            "Claim: united states deporting military veterans\n",
            "LLM's estimation: 0.0\n",
            "\n",
            "Claim: jews often victims hate crimes muslims united states\n",
            "LLM's estimation: 0.0\n",
            "\n",
            "Claim: jack benny arranged single red rose sent wife every day gone\n",
            "LLM's estimation: 0.5\n",
            "\n",
            "Number of 0.5s: 8\n",
            "accuracy = 0.66\n",
            "precision = 0.3157894736842105\n",
            "recall = 0.2222222222222222\n",
            "f1-score = 0.2608695652173913\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "examineLLM(CohereEmbeddings, flant5_llm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aVmJyab8qYv",
        "outputId": "9b2756b8-1127-4b3c-9111-2ee490e6052d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded successuflly: 6537 pages\n",
            "Filtred page in the following rand: [1, 145]\n",
            "Splitted documents into 435 chunks\n",
            "Generating answers with LLM\n",
            "\n",
            "Claim: best buy chain eschewing use word christmas 2006 holiday print advertising\n",
            "LLM's estimation: 0.0\n",
            "\n",
            "Claim: 1995 former president george hw bush resigned life member nra\n",
            "LLM's estimation: 0.0\n",
            "\n",
            "Claim: farmer expresses dissatisfaction crop prices carving message grain field\n",
            "LLM's estimation: 0.0\n",
            "\n",
            "Claim: walmart resold toys left donated needy kids\n",
            "LLM's estimation: 0.0\n",
            "\n",
            "Claim: 1988 author roald dahl penned open letter urging parents children vaccinated measles\n",
            "LLM's estimation: 0.0\n",
            "\n",
            "Claim: list safety tips offers effective counters victimized random violent crimes\n",
            "LLM's estimation: 1.0\n",
            "\n",
            "Claim: bill 1989 fleer baseball card includes hidden obscenity\n",
            "LLM's estimation: 0.0\n",
            "\n",
            "Claim: action star liam neeson gun control advocate\n",
            "LLM's estimation: 0.0\n",
            "\n",
            "Claim: photographs show amenities provided employees offices google\n",
            "LLM's estimation: 0.5\n",
            "\n",
            "Claim: disney replace damaged broken dvds small fee\n",
            "LLM's estimation: 0.0\n",
            "\n",
            "Claim: melba toast peach melba named opera singer\n",
            "LLM's estimation: 0.5\n",
            "\n",
            "Claim: tourist electrocuted crossing street las vegas\n",
            "LLM's estimation: 0.0\n",
            "\n",
            "Claim: actress martha raye entertained troops tended wounded soldiers field vietnam\n",
            "LLM's estimation: 0.0\n",
            "\n",
            "Claim: image shows magazines 1985 projection michael jackson would look like age 40\n",
            "LLM's estimation: 0.5\n",
            "\n",
            "Claim: worm stealing facebook credentials\n",
            "LLM's estimation: 0.0\n",
            "\n",
            "Claim: photograph shows man gored leg bull\n",
            "LLM's estimation: 0.0\n",
            "\n",
            "Claim: passengers airliner diverted cuba thought hijacking candid camera stunt due coincidental presence shows host allen funt\n",
            "LLM's estimation: 0.0\n",
            "\n",
            "Claim: 11 million deaths us since john lennon killed 8 december 1980\n",
            "LLM's estimation: 0.0\n",
            "\n",
            "Claim: charlie daniels author open letter hollywood bunch\n",
            "LLM's estimation: 0.0\n",
            "\n",
            "Claim: two television stations aired 2012 election results early\n",
            "LLM's estimation: 0.0\n",
            "\n",
            "Claim: pat tillmans brother kevin wrote essay us policy iraq\n",
            "LLM's estimation: 0.0\n",
            "\n",
            "Claim: pieces cheese nails boobytrapped treats found dog parks\n",
            "LLM's estimation: 0.0\n",
            "\n",
            "Claim: photograph shows small plane crashed tree next sign advertising flight lessons\n",
            "LLM's estimation: 0.0\n",
            "\n",
            "Claim: photograph shows baby hippo giant tortoise became friends captivity\n",
            "LLM's estimation: 0.0\n",
            "\n",
            "Claim: united states deporting military veterans\n",
            "LLM's estimation: 0.0\n",
            "\n",
            "Claim: jews often victims hate crimes muslims united states\n",
            "LLM's estimation: 0.0\n",
            "\n",
            "Claim: jack benny arranged single red rose sent wife every day gone\n",
            "LLM's estimation: 0.0\n",
            "\n",
            "Number of 0.5s: 4\n",
            "accuracy = 0.72\n",
            "precision = 0.3333333333333333\n",
            "recall = 0.037037037037037035\n",
            "f1-score = 0.06666666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I can use \"mmr\" (maximum marginal relevance) search_type instead of \"similarity\" for the retriever."
      ],
      "metadata": {
        "id": "JblC2xV0NKQc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PEFT"
      ],
      "metadata": {
        "id": "KEjhBItoFQWd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://colab.research.google.com/drive/1Mc8Gbd4xHllwsk3NbioXnLOcuA5TthZ0?usp=sharing"
      ],
      "metadata": {
        "id": "hrFmjt6NSo2m"
      }
    }
  ]
}